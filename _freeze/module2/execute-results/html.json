{
  "hash": "24e7ba3345d624f4255434084999de94",
  "result": {
    "engine": "knitr",
    "markdown": "# Module 2 — Decision Tree Analysis & Partial Dependence\n\n## Learning Outcomes\n\nBy the end of this module learners will be able to:\n  \n  - Explain how decision trees split data (Gini, entropy) and the difference between classification and regression trees.\n- Fit, visualize, prune, and evaluate decision tree models in R (`rpart`, `rpart.plot`).\n- Use cross-validation and `caret` for tuning and model selection.\n- Interpret model predictions using feature importance and Partial Dependence Plots (PDPs) with `pdp`, `iml`, and `DALEX`.\n- Write tests that validate model behavior on simple datasets.\n\n---\n  \n## 1. Setup & packages\n  \n\n::: {.cell}\n\n:::\n\n\n---\n  \n## 2. Decision tree basics (intuition)\n  \n  Short summary: trees recursively split the feature space to create homogeneous groups. Splits are chosen to maximize reduction in impurity (Gini or entropy for classification; MSE for regression).\n\n---\n  \n## 3. Building a classification tree (code-along)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Use the iris dataset and create a reproducible train/test split\ndata(iris)\ntrain_idx <- createDataPartition(iris$Species, p = 0.75, list = FALSE)\ntrain <- iris[train_idx, ]\ntest  <- iris[-train_idx, ]\n\n# Fit a simple rpart tree\nfit_rpart <- rpart(Species ~ ., data = train, method = \"class\", control = rpart.control(cp = 0.01))\n\n# Visualize the tree\nrpart.plot(fit_rpart, type = 3, extra = 104, fallen.leaves = TRUE)\n```\n\n::: {.cell-output-display}\n![](module2_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Predict and evaluate\npred_class <- predict(fit_rpart, test, type = \"class\")\ncm <- confusionMatrix(pred_class, test$Species)\ncm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   setosa versicolor virginica\n  setosa         12          0         0\n  versicolor      0         11         4\n  virginica       0          1         8\n\nOverall Statistics\n                                         \n               Accuracy : 0.8611         \n                 95% CI : (0.705, 0.9533)\n    No Information Rate : 0.3333         \n    P-Value [Acc > NIR] : 8.705e-11      \n                                         \n                  Kappa : 0.7917         \n                                         \n Mcnemar's Test P-Value : NA             \n\nStatistics by Class:\n\n                     Class: setosa Class: versicolor Class: virginica\nSensitivity                 1.0000            0.9167           0.6667\nSpecificity                 1.0000            0.8333           0.9583\nPos Pred Value              1.0000            0.7333           0.8889\nNeg Pred Value              1.0000            0.9524           0.8519\nPrevalence                  0.3333            0.3333           0.3333\nDetection Rate              0.3333            0.3056           0.2222\nDetection Prevalence        0.3333            0.4167           0.2500\nBalanced Accuracy           1.0000            0.8750           0.8125\n```\n\n\n:::\n:::\n\n\n**Teaching notes:** explain `cp` (complexity parameter), `minsplit`, `maxdepth`, and how pruning works. Use `printcp(fit_rpart)` and `plotcp(fit_rpart)` to choose cp.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprintcp(fit_rpart)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nClassification tree:\nrpart(formula = Species ~ ., data = train, method = \"class\", \n    control = rpart.control(cp = 0.01))\n\nVariables actually used in tree construction:\n[1] Petal.Length\n\nRoot node error: 76/114 = 0.66667\n\nn= 114 \n\n       CP nsplit rel error   xerror     xstd\n1 0.50000      0  1.000000 1.223684 0.054461\n2 0.46053      1  0.500000 0.723684 0.070201\n3 0.01000      2  0.039474 0.065789 0.028769\n```\n\n\n:::\n\n```{.r .cell-code}\nplotcp(fit_rpart)\n```\n\n::: {.cell-output-display}\n![](module2_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# prune to the cp with lowest xerror or the 1-SE rule\nopt_cp <- fit_rpart$cptable[which.min(fit_rpart$cptable[,\"xerror\"]), \"CP\"]\nfit_pruned <- prune(fit_rpart, cp = opt_cp)\nrpart.plot(fit_pruned, type = 3, extra = 104)\n```\n\n::: {.cell-output-display}\n![](module2_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n:::\n\n\n---\n\n## 4. Cross-validation and tuning with caret\n  \n\n::: {.cell}\n\n```{.r .cell-code}\nctrl <- trainControl(method = \"cv\", number = 5, classProbs = TRUE, summaryFunction = multiClassSummary)\nset.seed(42)\ntune_grid <- expand.grid(cp = seq(0.001, 0.05, by = 0.005))\ncaret_rpart <- train(Species ~ ., data = train, method = \"rpart\", trControl = ctrl, tuneGrid = tune_grid)\ncaret_rpart\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCART \n\n114 samples\n  4 predictor\n  3 classes: 'setosa', 'versicolor', 'virginica' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 92, 93, 90, 91, 90 \nResampling results across tuning parameters:\n\n  cp     logLoss   AUC        prAUC       Accuracy   Kappa      Mean_F1  \n  0.001  1.031016  0.9625794  0.04513889  0.9378411  0.9066523  0.9351836\n  0.006  1.031016  0.9625794  0.04513889  0.9378411  0.9066523  0.9351836\n  0.011  1.031016  0.9625794  0.04513889  0.9378411  0.9066523  0.9351836\n  0.016  1.031016  0.9625794  0.04513889  0.9378411  0.9066523  0.9351836\n  0.021  1.031016  0.9625794  0.04513889  0.9378411  0.9066523  0.9351836\n  0.026  1.031016  0.9625794  0.04513889  0.9378411  0.9066523  0.9351836\n  0.031  1.031016  0.9625794  0.04513889  0.9378411  0.9066523  0.9351836\n  0.036  1.031016  0.9625794  0.04513889  0.9378411  0.9066523  0.9351836\n  0.041  1.031016  0.9625794  0.04513889  0.9378411  0.9066523  0.9351836\n  0.046  1.031016  0.9625794  0.04513889  0.9378411  0.9066523  0.9351836\n  Mean_Sensitivity  Mean_Specificity  Mean_Pos_Pred_Value  Mean_Neg_Pred_Value\n  0.9369048         0.969127          0.9509259            0.9728704          \n  0.9369048         0.969127          0.9509259            0.9728704          \n  0.9369048         0.969127          0.9509259            0.9728704          \n  0.9369048         0.969127          0.9509259            0.9728704          \n  0.9369048         0.969127          0.9509259            0.9728704          \n  0.9369048         0.969127          0.9509259            0.9728704          \n  0.9369048         0.969127          0.9509259            0.9728704          \n  0.9369048         0.969127          0.9509259            0.9728704          \n  0.9369048         0.969127          0.9509259            0.9728704          \n  0.9369048         0.969127          0.9509259            0.9728704          \n  Mean_Precision  Mean_Recall  Mean_Detection_Rate  Mean_Balanced_Accuracy\n  0.9509259       0.9369048    0.3126137            0.9530159             \n  0.9509259       0.9369048    0.3126137            0.9530159             \n  0.9509259       0.9369048    0.3126137            0.9530159             \n  0.9509259       0.9369048    0.3126137            0.9530159             \n  0.9509259       0.9369048    0.3126137            0.9530159             \n  0.9509259       0.9369048    0.3126137            0.9530159             \n  0.9509259       0.9369048    0.3126137            0.9530159             \n  0.9509259       0.9369048    0.3126137            0.9530159             \n  0.9509259       0.9369048    0.3126137            0.9530159             \n  0.9509259       0.9369048    0.3126137            0.9530159             \n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was cp = 0.046.\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(caret_rpart)\n```\n\n::: {.cell-output-display}\n![](module2_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# evaluate on test\npred_caret <- predict(caret_rpart, test)\nconfusionMatrix(pred_caret, test$Species)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   setosa versicolor virginica\n  setosa         12          0         0\n  versicolor      0         11         4\n  virginica       0          1         8\n\nOverall Statistics\n                                         \n               Accuracy : 0.8611         \n                 95% CI : (0.705, 0.9533)\n    No Information Rate : 0.3333         \n    P-Value [Acc > NIR] : 8.705e-11      \n                                         \n                  Kappa : 0.7917         \n                                         \n Mcnemar's Test P-Value : NA             \n\nStatistics by Class:\n\n                     Class: setosa Class: versicolor Class: virginica\nSensitivity                 1.0000            0.9167           0.6667\nSpecificity                 1.0000            0.8333           0.9583\nPos Pred Value              1.0000            0.7333           0.8889\nNeg Pred Value              1.0000            0.9524           0.8519\nPrevalence                  0.3333            0.3333           0.3333\nDetection Rate              0.3333            0.3056           0.2222\nDetection Prevalence        0.3333            0.4167           0.2500\nBalanced Accuracy           1.0000            0.8750           0.8125\n```\n\n\n:::\n:::\n\n\n**Notes:** `caret::train` automates CV and tuning. Explain multiClassSummary (accuracy, Kappa, etc.).\n\n---\n  \n## 5. Feature importance & interpretation\n  \n\n::: {.cell}\n\n```{.r .cell-code}\n# Variable importance from rpart:\nvarImp(fit_rpart)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              Overall\nPetal.Length 70.25918\nPetal.Width  70.25918\nSepal.Length 35.26587\nSepal.Width  20.46939\n```\n\n\n:::\n\n```{.r .cell-code}\n# For caret model:\nvarImp(caret_rpart)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nrpart variable importance\n\n             Overall\nPetal.Width   100.00\nPetal.Length  100.00\nSepal.Length   29.72\nSepal.Width     0.00\n```\n\n\n:::\n:::\n\n\nDiscuss how importance is computed (split improvement) and limitations.\n\n---\n  \n## 6. Partial Dependence Plots (PDPs)\n  \n**Goal:** show marginal effect of a feature on predicted probability (or prediction) while averaging out other features.\n\n### 6.1 PDP with `pdp`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Use the caret-trained model (wrap predict function if necessary)\n# pdp works with models that have a predict method returning probabilities. We'll use the randomForest wrapper as an example.\nrf <- randomForest(Species ~ ., data = train)\n\n# Partial dependence for Petal.Length vs class setosa (probability)\npdp_pl <- partial(rf, pred.var = \"Petal.Length\", plot = TRUE, prob = TRUE, which.class = \"setosa\")\nprint(pdp_pl)\n```\n\n::: {.cell-output-display}\n![](module2_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n### 6.2 PDP with `DALEX`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create an explainer\nexplainer_rf <- explain(rf, data = train[,1:4], y = train$Species, label = \"rf_iris\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPreparation of a new explainer is initiated\n  -> model label       :  rf_iris \n  -> data              :  114  rows  4  cols \n  -> target variable   :  114  values \n  -> predict function  :  yhat.randomForest  will be used (  default  )\n  -> predicted values  :  No value for predict function target column. (  default  )\n  -> model_info        :  package randomForest , ver. 4.7.1.1 , task multiclass (  default  ) \n  -> predicted values  :  predict function returns multiple columns:  3  (  default  ) \n  -> residual function :  difference between 1 and probability of true class (  default  )\n  -> residuals         :  numerical, min =  0 , mean =  0.01891228 , max =  0.34  \n  A new explainer has been created!  \n```\n\n\n:::\n\n```{.r .cell-code}\n# Profile (partial dependence) using DALEX\np <- model_profile(explainer_rf, variables = \"Petal.Length\", N = 50)\nplot(p)\n```\n\n::: {.cell-output-display}\n![](module2_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n**Teaching caveats:** PDPs show average marginal effects and can be misleading with strong feature interactions. Use two-way PDPs or ICE plots for heterogeneity.\n\n---\n  \n## 7. Individual Conditional Expectation (ICE) and 2D PDPs\n  \n\n::: {.cell}\n\n```{.r .cell-code}\n# ICE using pdp\nice_pl <- partial(rf, pred.var = \"Petal.Length\", ice = TRUE, plot = TRUE, which.class = \"setosa\")\n\n# 2D PDP for Petal.Length and Petal.Width\npdp_2d <- partial(rf, pred.var = c(\"Petal.Length\", \"Petal.Width\"), chull = TRUE)\nplotPartial(pdp_2d)\n```\n\n::: {.cell-output-display}\n![](module2_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n---\n  \n## 8. Model comparison: Decision Tree vs Random Forest\n  \n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Random Forest and compare\nrf_fit <- randomForest(Species ~ ., data = train)\npred_rf <- predict(rf_fit, test)\ncm_rf <- confusionMatrix(pred_rf, test$Species)\ncm_tab <- rbind(tree = cm$overall[names(cm$overall) == \"Accuracy\"], rf = cm_rf$overall[names(cm_rf$overall) == \"Accuracy\"])\ncm_tab\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Accuracy\ntree 0.8611111\nrf   0.9444444\n```\n\n\n:::\n:::\n\n\nDiscuss trade-offs: interpretability (tree) vs performance (RF), stability, and overfitting.\n\n---\n  \n## 9. Automated tests for classroom (sanity checks)\n  \n\n::: {.cell}\n\n```{.r .cell-code}\n# 1) Ensure tree predictions have reasonable accuracy (> 0.7 on iris test)\nacc_tree <- cm$overall[\"Accuracy\"]\nstopifnot(acc_tree >= 0.7)\n\n# 2) PDP returns a data.frame and includes Petal.Length values\npdp_res <- partial(rf, pred.var = \"Petal.Length\", prob = TRUE, which.class = \"setosa\", plot = FALSE)\nstopifnot(is.data.frame(pdp_res))\nstopifnot(\"Petal.Length\" %in% names(pdp_res))\n\nlist(tests = \"all passed\", tree_accuracy = acc_tree)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$tests\n[1] \"all passed\"\n\n$tree_accuracy\n Accuracy \n0.8611111 \n```\n\n\n:::\n:::\n\n\n---\n  \n## 10. Exercises and in-class tasks\n  \n**Exercise A:** Build and prune a decision tree on the `wine` or `iris` dataset; show how pruning affects depth and accuracy.\n\n**Exercise B:** Compute PDPs for two top features in a caret-tuned model and interpret whether they are monotonic or have thresholds.\n\n**Exercise C (advanced):** Use `iml` to compute Shapley values for a small set of observations and compare with PDP insights.\n\n---\n  \n<!-- ## 11. Suggested slide/demo flow -->\n  \n<!-- 1. Briefly explain splits and impurity. -->\n<!-- 2. Live-code building a tree and visualizing it. -->\n<!-- 3. Show pruning and cross-validation. -->\n<!-- 4. Fit a random forest and compare performance. -->\n<!-- 5. Demonstrate PDPs and ICE plots; discuss interpretation. -->\n\n---\n  \n*End of Module 2 — Decision Tree Analysis & Partial Dependence*\n  \n  \n  ",
    "supporting": [
      "module2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}